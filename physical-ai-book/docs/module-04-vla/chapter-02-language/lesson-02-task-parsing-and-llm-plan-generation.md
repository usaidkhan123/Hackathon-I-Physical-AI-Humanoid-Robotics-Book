---
id: lesson-02-task-parsing-and-llm-plan-generation
title: "Lesson 2: Task Parsing and LLM Plan Generation"
sidebar_position: 2
description: Learn to generate multi-step robotic action plans from high-level natural language commands using LLMs.
---

# Lesson 2: Task Parsing and LLM Plan Generation

## Lesson Objectives
- Understand how to decompose complex human commands into a sequence of simpler, robot-executable steps.
- Learn prompt engineering techniques for guiding LLMs to generate structured task plans.
- Implement a ROS 2 node to manage and interpret multi-step plans generated by an LLM.

## Prerequisites
- Completion of Lesson 1: Intent Detection with LLMs.
- Familiarity with ROS 2 actions and services.
- Python programming skills and LLM API interaction.

## Concept Explanation
Many real-world robotic tasks are not single actions but rather sequences of actions (e.g., "Go to the kitchen, pick up the cup, and bring it to me"). Task parsing involves breaking down a high-level command into these smaller, atomic steps. Large Language Models can be prompted to generate such structured plans, outlining the order of operations and necessary parameters for each step. This transforms an abstract human request into a concrete, executable robot plan.

<h2>Step-by-Step Technical Breakdown</h2>

1.  **Define Action Primitives**: Create a list of fundamental actions your robot can perform (e.g., `navigate_to`, `open_gripper`, `close_gripper`, `detect_object`).
2.  **Prompt for Plan Generation**: Craft an LLM prompt that instructs the model to generate a sequence of these action primitives, complete with parameters, to achieve a given high-level goal. Specify the desired output format (e.g., JSON array of actions).
3.  **LLM Interaction**: Send the user's high-level command to the LLM and receive the generated plan.
4.  **ROS 2 Plan Manager Node**: Develop a ROS 2 node that subscribes to the detected intent (or direct text command), calls the LLM for a plan, and then parses and manages the execution of this multi-step plan. This node will sequentially dispatch commands to other ROS 2 action/service servers.

<h2>Real-World Analogy</h2>
Think of giving a recipe to a chef (robot). You don't tell the chef every tiny movement; you give high-level instructions like "Make a lasagna." The chef (LLM) then breaks that down into a sequence of steps: "Preheat oven," "Boil noodles," "Prepare sauce," etc. Task parsing is that process of breaking down the "lasagna" command into its constituent parts.

<h2>Hands-On Tasks</h2>
1.  Extend your `intent_detector_node.py` or create a new `task_planner_node.py` that takes a high-level command (e.g., "Fetch me a book from the living room shelf") and prompts an LLM to generate a sequence of robot actions.
2.  Define a JSON structure for your robot's action primitives and the generated plan.
3.  Implement logic in your node to parse the LLM's JSON plan and print out each step.
4.  (Optional) Start thinking about how this node would dispatch actual ROS 2 commands.

<h2>Python + ROS2 Examples</h2>

```python
# task_planner_node.py
import rclpy
from rclpy.node import Node
from std_msgs.msg import String
import openai
import json
import os
import time

# Placeholder for a custom ROS 2 message type for a structured plan
# For now, we'll use a String message to publish a JSON representation of the plan
# from robot_msgs.msg import RobotTaskPlan # Example custom message type

class TaskPlannerNode(Node):
    def __init__(self):
        super().__init__('task_planner_node')
        self.subscription = self.create_subscription(
            String,
            'voice_command_text', # Subscribe to raw text from STT or processed intent
            self.listener_callback,
            10
        )
        self.publisher_ = self.create_publisher(String, 'robot_task_plan', 10) # Publishing JSON string
        self.get_logger().info('Task Planner Node started. Waiting for commands to plan...')

        self.openai_client = openai.OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

    def generate_robot_plan(self, high_level_command):
        # Define a simplified set of robot capabilities/action primitives
        action_primitives = [
            {"name": "navigate_to", "description": "Move the robot to a specific location.", "parameters": {"location": "string"}},
            {"name": "open_gripper", "description": "Open the robot's gripper."},
            {"name": "close_gripper", "description": "Close the robot's gripper to grasp an object.", "parameters": {"object": "string"}},
            {"name": "detect_object", "description": "Use sensors to detect a specific object.", "parameters": {"object": "string"}},
            {"name": "report_status", "description": "Report the robot's current status or findings."}
        ]

        prompt = f"""
        You are a robot task planner. Your goal is to convert a high-level human command into a sequential plan of robot actions.
        The robot can perform the following action primitives:
        {json.dumps(action_primitives, indent=2)}

        High-level human command: "{high_level_command}"

        Generate a plan as a JSON array of actions. Each action should be an object with an "action" key (matching one of the primitive names) and a "parameters" object if applicable.
        Example response format:
        [
            {{"action": "navigate_to", "parameters": {{"location": "kitchen"}}}},
            {{"action": "detect_object", "parameters": {{"object": "apple"}}}},
            {{"action": "grasp_object", "parameters": {{"object": "apple"}}}},
            {{"action": "navigate_to", "parameters": {{"location": "human"}}}},
            {{"action": "report_status", "parameters": {{"message": "Task completed."}}}}
        ]
        If the command is unclear or cannot be planned, return an empty array or a single "report_status" action with an error message.
        """

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini", # Or another suitable model
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": high_level_command}
                ],
                response_format={"type": "json_object"}
            )
            plan_str = response.choices[0].message.content
            # The API returns a JSON *string*, so we need to parse it again
            return json.loads(plan_str) 
        except Exception as e:
            self.get_logger().error(f"LLM API call for plan generation failed: {e}")
            return [{"action": "report_status", "parameters": {"message": f"Planning failed: {e}"}}]

    def listener_callback(self, msg):
        self.get_logger().info(f'Received command for planning: "{msg.data}"')
        
        # In a real system, you might get this from the intent detector
        # For this lesson, we'll assume the incoming String msg.data is the high-level command
        high_level_command = msg.data

        robot_plan = self.generate_robot_plan(high_level_command)
        
        plan_msg = String() # Using String to publish JSON for simplicity
        plan_msg.data = json.dumps(robot_plan)
        self.publisher_.publish(plan_msg)
        self.get_logger().info(f'Published plan: "{plan_msg.data}"')

def main(args=None):
    rclpy.init(args=args)
    task_planner_node = TaskPlannerNode()
    rclpy.spin(task_planner_node)
    task_planner_node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```

## Debugging Tips
-   **Prompt Iteration**: Generating good plans with LLMs often requires iterative prompt refinement. Test with various complex commands and adjust your prompt until the desired plan structure is consistently produced.
-   **Parameter Consistency**: Ensure that the parameters generated by the LLM for each action exactly match the expected parameters of your robot's action primitives.
-   **Error Handling**: Implement robust error handling for cases where the LLM might return malformed JSON or an illogical plan.
-   **Visualization**: Visualize the generated plan in a human-readable format to quickly identify any issues with the LLM's logic.

## Mini Quiz (4-6 questions)
1.  What is the main goal of task parsing in VLA robotics?
2.  Why are LLMs well-suited for generating multi-step robotic plans?
3.  What are "action primitives" in the context of robot planning?
4.  Describe a common format for an LLM to output a robotic task plan.
5.  What could be a role of a "ROS 2 Plan Manager Node"?
