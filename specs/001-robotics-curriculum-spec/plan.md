# Production Plan: Physical AI & Humanoid Robotics Book & API

**Branch**: `001-robotics-curriculum-spec` | **Generated**: 2025-12-07 | **Status**: Approved

This document provides an explicit, engineer-level development plan for the Docusaurus book and its accompanying FastAPI backend.

---

## Phase 1: Docusaurus Site Implementation

### 1.1. Project Initialization & TypeScript Conversion

**Objective**: Create a new Docusaurus site with a TypeScript-first configuration.

**Commands**:

1.  **Initialize Docusaurus Classic Site**:
    ```bash
    npm create docusaurus@latest physical-ai-book classic
    ```

2.  **Navigate to Project Directory**:
    ```bash
    cd physical-ai-book
    ```

3.  **Install TypeScript Dependencies**:
    ```bash
    npm install --save-dev typescript @docusaurus/module-type-aliases @docusaurus/tsconfig @types/react
    ```

4.  **Generate `tsconfig.json`**:
    ```bash
    npx tsc --init
    ```
    *Post-condition*: A `tsconfig.json` file is created in the project root.

5.  **Convert Key Files to TypeScript**: Rename the following files from `.js` to `.tsx` (or `.ts` for config):
    *   `docusaurus.config.js` → `docusaurus.config.ts`
    *   `src/pages/index.js` → `src/pages/index.tsx`
    *   `src/theme/Root.js` → `src/theme/Root.tsx`

### 1.2. `docusaurus.config.ts` Configuration

**Objective**: Configure the site's metadata, presets, and theme.

**File**: `docusaurus.config.ts`

**Implementation**:

```typescript
import {themes as prismThemes} from 'prism-react-renderer';
import type {Config} from '@docusaurus/types';
import type * as Preset from '@docusaurus/preset-classic';

const config: Config = {
  title: 'Physical AI & Humanoid Robotics',
  tagline: 'From Digital Brain to Embodied Intelligence',
  favicon: 'img/favicon.ico',

  // Set the production url of your site here
  url: 'https://your-production-url.com',
  // Set the /<baseUrl>/ pathname under which your site is served
  baseUrl: '/',

  organizationName: 'your-org', // Usually your GitHub org/user name.
  projectName: 'physical-ai-book', // Usually your repo name.

  onBrokenLinks: 'throw',
  onBrokenMarkdownLinks: 'warn',

  i18n: {
    defaultLocale: 'en',
    locales: ['en'],
  },

  presets: [
    [
      'classic',
      {
        docs: {
          routeBasePath: '/', // Serve the docs at the site's root
          sidebarPath: './sidebars.ts',
          // Please change this to your repo.
          editUrl:
            'https://github.com/your-org/physical-ai-book/tree/main/',
        },
        blog: false, // Disable the blog plugin
        theme: {
          customCss: './src/css/custom.css',
        },
      } satisfies Preset.Options,
    ],
  ],

  themeConfig: {
    image: 'img/docusaurus-social-card.jpg',
    navbar: {
      title: 'Physical AI',
      logo: {
        alt: 'My Site Logo',
        src: 'img/logo.svg',
      },
      items: [
        {
          type: 'docSidebar',
          sidebarId: 'tutorialSidebar',
          position: 'left',
          label: 'Curriculum',
        },
        {
          href: 'https://github.com/your-org/physical-ai-book',
          label: 'GitHub',
          position: 'right',
        },
      ],
    },
    footer: {
      style: 'dark',
      links: [ /* Footer links can be added here */ ],
      copyright: `Copyright © ${new Date().getFullYear()} My Project, Inc. Built with Docusaurus.`, 
    },
    prism: {
      theme: prismThemes.github,
      darkTheme: prismThemes.dracula,
    },
  } satisfies Preset.ThemeConfig,
};

export default config;
```

### 1.3. Automated Sidebar Generation

**Objective**: Configure the sidebar to automatically generate from the `docs/` directory structure.

**File**: `sidebars.ts`

**Implementation**:

```typescript
import type {SidebarsConfig} from '@docusaurus/plugin-content-docs';

/**
 * Creating a sidebar enables you to:
 - create an ordered group of docs
 - render a sidebar for each doc of that group
 - provide next/previous navigation

 The sidebars can be generated from the filesystem, or explicitly defined here.

 Create as many sidebars as you want.
 */
const sidebars: SidebarsConfig = {
  // By default, Docusaurus generates a sidebar from the docs folder structure
  tutorialSidebar: [{type: 'autogenerated', dirName: '.'}],

  // But you can create a sidebar manually
  /*
  tutorialSidebar: [
    'intro',
    'hello',
    {
      type: 'category',
      label: 'Tutorial',
      items: ['tutorial-basics/create-a-document'],
    },
  ],
   */
};

export default sidebars;
```

### 1.4. Content Scaffolding and Versioning

**Objective**: Create the book's directory structure and enable versioning.

**Commands**:

1.  **Create Directory Structure** (run from `physical-ai-book` root):
    *This script generates all required module, chapter, and lesson markdown files.*
    ```bash
    mkdir -p docs/module-01-ros2/chapter-01-foundations docs/module-01-ros2/chapter-02-ros2-core docs/module-01-ros2/chapter-03-rclpy-bridge docs/module-01-ros2/chapter-04-urdf-design && \
    mkdir -p docs/module-02-simulation/chapter-01-gazebo-basics docs/module-02-simulation/chapter-02-unity-visualization docs/module-02-simulation/chapter-03-sensor-simulation docs/module-02-simulation/chapter-04-digital-twin && \
    mkdir -p docs/module-03-nvidia-isaac/chapter-01-isaac-sim docs/module-03-nvidia-isaac/chapter-02-isaac-ros docs/module-03-nvidia-isaac/chapter-03-nav2 docs/module-03-nvidia-isaac/chapter-04-sim-to-real && \
    mkdir -p docs/module-04-vla/chapter-01-voice docs/module-04-vla/chapter-02-language docs/module-04-vla/chapter-03-action docs/module-04-vla/chapter-04-capstone && \
    touch docs/intro.md && \
    touch docs/module-01-ros2/chapter-01-foundations/lesson-01-what-is-physical-ai.md docs/module-01-ros2/chapter-01-foundations/lesson-02-embodied-intelligence.md docs/module-01-ros2/chapter-01-foundations/lesson-03-human-vs-robot-agency.md docs/module-01-ros2/chapter-01-foundations/lesson-04-sensor-overview.md && \
    touch docs/module-01-ros2/chapter-02-ros2-core/lesson-01-nodes.md docs/module-01-ros2/chapter-02-ros2-core/lesson-02-topics.md docs/module-01-ros2/chapter-02-ros2-core/lesson-03-services.md docs/module-01-ros2/chapter-02-ros2-core/lesson-04-actions.md && \
    touch docs/module-01-ros2/chapter-03-rclpy-bridge/lesson-01-python-to-ros.md docs/module-01-ros2/chapter-03-rclpy-bridge/lesson-02-robot-controllers.md docs/module-01-ros2/chapter-03-rclpy-bridge/lesson-03-message-types.md docs/module-01-ros2/chapter-03-rclpy-bridge/lesson-04-debugging-tools.md && \
    touch docs/module-01-ros2/chapter-04-urdf-design/lesson-01-urdf-basics.md docs/module-01-ros2/chapter-04-urdf-design/lesson-02-humanoid-joints.md docs/module-01-ros2/chapter-04-urdf-design/lesson-03-sensors-in-urdf.md docs/module-01-ros2/chapter-04-urdf-design/lesson-04-testing-models.md && \
    touch docs/module-02-simulation/chapter-01-gazebo-basics/lesson-01-installation.md docs/module-02-simulation/chapter-01-gazebo-basics/lesson-02-world-building.md docs/module-02-simulation/chapter-01-gazebo-basics/lesson-03-gravity-and-collisions.md docs/module-02-simulation/chapter-01-gazebo-basics/lesson-04-plugin-system.md && \
    touch docs/module-02-simulation/chapter-02-unity-visualization/lesson-01-unity-setup.md docs/module-02-simulation/chapter-02-unity-visualization/lesson-02-human-robot-interaction.md docs/module-02-simulation/chapter-02-unity-visualization/lesson-03-animation-sync.md docs/module-02-simulation/chapter-02-unity-visualization/lesson-04-render-pipelines.md && \
    touch docs/module-02-simulation/chapter-03-sensor-simulation/lesson-01-lidar-sim.md docs/module-02-simulation/chapter-03-sensor-simulation/lesson-02-depth-cameras.md docs/module-02-simulation/chapter-03-sensor-simulation/lesson-03-imu-sim.md docs/module-02-simulation/chapter-03-sensor-simulation/lesson-04-noise-models.md && \
    touch docs/module-02-simulation/chapter-04-digital-twin/lesson-01-environment-replication.md docs/module-02-simulation/chapter-04-digital-twin/lesson-02-domain-randomization.md docs/module-02-simulation/chapter-04-digital-twin/lesson-03-performance-optimization.md docs/module-02-simulation/chapter-04-digital-twin/lesson-04-validation-testing.md && \
    touch docs/module-03-nvidia-isaac/chapter-01-isaac-sim/lesson-01-installation.md docs/module-03-nvidia-isaac/chapter-01-isaac-sim/lesson-02-omniverse-assets.md docs/module-03-nvidia-isaac/chapter-01-isaac-sim/lesson-03-synthetic-data.md docs/module-03-nvidia-isaac/chapter-01-isaac-sim/lesson-04-domain-lighting.md && \
    touch docs/module-03-nvidia-isaac/chapter-02-isaac-ros/lesson-01-vslam.md docs/module-03-nvidia-isaac/chapter-02-isaac-ros/lesson-02-hardware-acceleration.md docs/module-03-nvidia-isaac/chapter-02-isaac-ros/lesson-03-camera-pipelines.md docs/module-03-nvidia-isaac/chapter-02-isaac-ros/lesson-04-gpu-offloading.md && \
    touch docs/module-03-nvidia-isaac/chapter-03-nav2/lesson-01-path-planning.md docs/module-03-nvidia-isaac/chapter-03-nav2/lesson-02-bipedal-walking.md docs/module-03-nvidia-isaac/chapter-03-nav2/lesson-03-obstacle-avoidance.md docs/module-03-nvidia-isaac/chapter-03-nav2/lesson-04-recovery-behaviors.md && \
    touch docs/module-03-nvidia-isaac/chapter-04-sim-to-real/lesson-01-transfer-learning.md docs/module-03-nvidia-isaac/chapter-04-sim-to-real/lesson-02-noise-injection.md docs/module-03-nvidia-isaac/chapter-04-sim-to-real/lesson-03-hardware-constraints.md docs/module-03-nvidia-isaac/chapter-04-sim-to-real/lesson-04-real-world-validation.md && \
    touch docs/module-04-vla/chapter-01-voice/lesson-01-whisper-integration.md docs/module-04-vla/chapter-01-voice/lesson-02-audio-preprocessing.md docs/module-04-vla/chapter-01-voice/lesson-03-wake-words.md docs/module-04-vla/chapter-01-voice/lesson-04-latency-optimization.md && \
    touch docs/module-04-vla/chapter-02-language/lesson-01-intent-detection.md docs/module-04-vla/chapter-02-language/lesson-02-task-parsing.md docs/module-04-vla/chapter-02-language/lesson-03-sequence-generation.md docs/module-04-vla/chapter-02-language/lesson-04-error-correction.md && \
    touch docs/module-04-vla/chapter-03-action/lesson-01-ros2-task-execution.md docs/module-04-vla/chapter-03-action/lesson-02-motion-primitives.md docs/module-04-vla/chapter-03-action/lesson-03-grasp-planning.md docs/module-04-vla/chapter-03-action/lesson-04-failure-handling.md && \
    touch docs/module-04-vla/chapter-04-capstone/lesson-01-full-pipeline.md docs/module-04-vla/chapter-04-capstone/lesson-02-testing-sim.md docs/module-04-vla/chapter-04-capstone/lesson-03-real-hardware.md docs/module-04-vla/chapter-04-capstone/lesson-04-demo-preparation.md
    ```

2.  **Enable Versioning**: 
    *This command creates a `1.0.0` version of the docs. Future changes should be made in the main `docs` directory.*
    ```bash
    npm run docusaurus docs:version 1.0.0
    ```
    *Post-condition*:
    *   `versioned_docs/version-1.0.0/` directory is created.
    *   `versions.json` is created in the root.

---

## Phase 2: FastAPI & RAG Backend

### 2.1. Project Structure

**Objective**: Establish a clean directory structure for the FastAPI application.

```
/backend
  /app
    /api
      __init__.py
      endpoints.py
    /core
      __init__.py
      config.py
      security.py
    /services
      __init__.py
      chunking.py
      embedding.py
      qdrant_service.py
      postgres_service.py
    /models
      __init__.py
      api_models.py
      db_models.py
    __init__.py
    main.py
  .env
  requirements.txt
```

### 2.2. FastAPI Endpoints & Models

**Objective**: Define the API contract with request and response models.

**File**: `backend/app/models/api_models.py`

```python
from pydantic import BaseModel, Field
from typing import List, Dict, Any
import uuid

class EmbedRequest(BaseModel):
    content: str
    source: str = Field(..., description="e.g., 'module-01/chapter-02/lesson-03.md'")

class EmbedResponse(BaseModel):
    status: str = "success"
    vector_id: str

class SearchRequest(BaseModel):
    query: str
    top_k: int = 5

class SearchResult(BaseModel):
    source: str
    content: str
    score: float

class SearchResponse(BaseModel):
    results: List[SearchResult]

class ChatRequest(BaseModel):
    user_id: uuid.UUID
    chat_id: uuid.UUID | None = None
    message: str

class ChatResponse(BaseModel):
    chat_id: uuid.UUID
    response: str
    sources: List[SearchResult]
```

**File**: `backend/app/api/endpoints.py` (signatures only)
```python
from fastapi import APIRouter, Depends, HTTPException
from ..models import api_models
from ..services import embedding, qdrant_service, postgres_service

router = APIRouter()

@router.post("/embed", response_model=api_models.EmbedResponse)
async def embed_content(request: api_models.EmbedRequest):
    # 1. Chunk content from request.content
    # 2. Embed chunks using embedding.py
    # 3. Upsert vectors to Qdrant via qdrant_service.py
    # 4. Return vector ID from Qdrant
    pass

@router.post("/search", response_model=api_models.SearchResponse)
async def search_content(request: api_models.SearchRequest):
    # 1. Embed request.query
    # 2. Search Qdrant for top_k results
    # 3. Format and return results
    pass

@router.post("/chat", response_model=api_models.ChatResponse)
async def chat_with_rag(request: api_models.ChatRequest):
    # 1. Log user message in Postgres
    # 2. Search content with request.message
    # 3. Construct prompt for OpenAI with retrieved context
    # 4. Get response from OpenAI
    # 5. Log AI response in Postgres
    # 6. Return response and sources
    pass
```

### 2.3. Qdrant Vector Store Configuration

**Objective**: Define the schema for the vector collection.

-   **Collection Name**: `physical_ai_book_v1`
-   **Vector Size**: `1536` (for OpenAI `text-embedding-ada-002`)
-   **Distance Metric**: `Cosine`
-   **Payload Schema**:
    ```json
    {
      "source": "string", // "module-01/chapter-02/lesson-03.md"
      "chapter": "string", // "chapter-02-ros2-core"
      "module": "string", // "module-01-ros2"
      "content_hash": "string" // MD5 hash of the chunk content
    }
    ```

### 2.4. Neon Postgres SQL Schema

**Objective**: Define the relational schema for user and chat management.

**SQL Statements**:
```sql
-- Users table to track interactions
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    last_seen_at TIMESTAMPTZ
);

-- Chats table to group conversations
CREATE TABLE chats (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    title VARCHAR(255) NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- Message logs for every user query and AI response
CREATE TABLE message_logs (
    id BIGSERIAL PRIMARY KEY,
    chat_id UUID NOT NULL REFERENCES chats(id) ON DELETE CASCADE,
    role VARCHAR(50) NOT NULL, -- 'user' or 'assistant'
    content TEXT NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    retrieved_sources JSONB -- Store the list of SearchResult objects
);

-- Indexes for performance
CREATE INDEX idx_chats_user_id ON chats(user_id);
CREATE INDEX idx_message_logs_chat_id ON message_logs(chat_id);
```

### 2.5. Text Chunking Strategy

**Objective**: Define the methodology for splitting markdown content into embeddable chunks.

-   **Strategy**: Recursive Character Text Splitting, aware of Markdown syntax.
-   **Primary Separators**: `\n\n`, `\n`, ` `
-   **Chunk Size**: `1000` tokens
-   **Chunk Overlap**: `200` tokens
-   **Metadata Tracking**: Each chunk MUST be associated with its source file (`source`) and other payload fields. A hash of the content (`content_hash`) will be stored to detect changes and trigger re-embedding.

---
